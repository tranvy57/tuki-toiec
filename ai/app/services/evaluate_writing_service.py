"""
Standalone service for evaluating TOEIC writing with personalization support.
This service uses utilities from RouteNode but is independent from chat workflow.
"""

from typing import Dict, Any, Optional, List
from app.configs.model_config import Gemini
from app.services.qdrant_service import QdrantService
from app.db.session import get_db_session
import json
import re

try:
    from app.models.user_profile import get_personalization_context
    from app.services.db_profile_service import DatabaseProfileService
    PERSONALIZATION_AVAILABLE = True
except ImportError:
    PERSONALIZATION_AVAILABLE = False
    get_personalization_context = None
    DatabaseProfileService = None

# Optional sklearn imports for TF-IDF/MMR
try:
    from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS
    from sklearn.metrics.pairwise import cosine_similarity
    import numpy as np
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    TfidfVectorizer = None
    cosine_similarity = None
    np = None


class EvaluateWritingService:
    """
    Standalone service for evaluating TOEIC writing.
    Provides personalized feedback based on user profile and RAG-enhanced context.
    """
    
    def __init__(self):
        """Initialize the service with AI model and supporting services."""
        try:
            self._gemini = Gemini()
            self._llm = self._gemini.llm()
            self._vector_service = QdrantService()
            self._db_session = get_db_session()
            
            # Initialize profile service if available
            if PERSONALIZATION_AVAILABLE and self._db_session:
                self._db_profile_service = DatabaseProfileService(self._db_session)
            else:
                self._db_profile_service = None
                
        except Exception as e:
            raise Exception(f"Failed to initialize EvaluateWritingService: {str(e)}")
    
    def _refine_query_with_tfidf_mmr(self, query: str, corpus: List[str] = None, top_n=10, Î»=0.7) -> str:
        """
        LÃ m giÃ u query:
        - TF-IDF láº¥y keywords quan trá»ng
        - MMR chá»n keywords Ä‘a dáº¡ng
        - Loáº¡i bá» conversational noise (hello, tuki, don know...)
        """
        if not SKLEARN_AVAILABLE or not query.strip():
            return query

        try:
            # ---------------------------
            # 1. STOPWORDS TÃ™Y CHá»ˆNH
            # ---------------------------
            custom_stopwords = {
                "hello", "hi", "hey", "tuki",
                "don", "dont", "don't", "know", "i", "me",
                "please", "tell", "explain", "help",
                "what", "how", "why", "when", "where", "who",
                "idk", "ok", "okay", "yeah", "yep",
                "uh", "um", "hmm"
            }

            stopwords = list(ENGLISH_STOP_WORDS.union(custom_stopwords))

            # ---------------------------
            # 2. CORPUS TOEIC máº·c Ä‘á»‹nh
            # ---------------------------
            if corpus is None:
                corpus = [
                    "TOEIC listening comprehension practice",
                    "TOEIC reading comprehension strategies",
                    "TOEIC grammar rules and examples",
                    "TOEIC vocabulary building exercises",
                    "TOEIC test preparation tips",
                    "TOEIC speaking practice methods",
                    "TOEIC writing skills improvement"
                ]

            # ---------------------------
            # 3. TF-IDF CLEAN + UNIGRAM
            # ---------------------------
            vectorizer = TfidfVectorizer(
                ngram_range=(1, 1),      # chá»‰ láº¥y unigram â†’ trÃ¡nh bigram rÃ¡c
                stop_words=stopwords,
                max_features=500,
                lowercase=True
            )

            all_texts = corpus + [query]
            tfidf = vectorizer.fit_transform(all_texts)

            feature_names = vectorizer.get_feature_names_out()
            query_vec = tfidf[-1].toarray()[0]

            # Top TF-IDF terms
            top_indices = np.argsort(query_vec)[::-1][:top_n]
            top_terms = [feature_names[i] for i in top_indices if query_vec[i] > 0]

            if len(top_terms) < 2:
                return query

            # ---------------------------
            # 4. MMR CHá»ŒN KEYWORDS CHÃNH
            # ---------------------------
            term_vecs = vectorizer.transform(top_terms).toarray()
            query_center = np.mean(term_vecs, axis=0)

            selected_ids = self._mmr_select(
                query_center,
                term_vecs,
                Î»=Î»,
                top_k=min(5, len(term_vecs))
            )

            selected_terms = [top_terms[i] for i in selected_ids]

            refined_query = f"{query}. Related TOEIC concepts: {', '.join(selected_terms)}"

            print(f"ğŸ” Query refinement: {selected_terms} -> {len(selected_terms)} terms added")
            return refined_query

        except Exception as e:
            print(f"âŒ TF-IDF/MMR Error: {e}")
            return query
    
    def _mmr_select(self, query_vec, candidate_vecs, Î»=0.7, top_k=5):
        """Maximum Marginal Relevance selection for diversity."""
        if not SKLEARN_AVAILABLE:
            return list(range(min(top_k, len(candidate_vecs))))
        
        sim_query = cosine_similarity([query_vec], candidate_vecs)[0]
        sim_cand = cosine_similarity(candidate_vecs)

        selected = []
        candidates = list(range(len(candidate_vecs)))

        while len(selected) < top_k and candidates:
            scores = [
                Î» * sim_query[i] - (1 - Î») * max([sim_cand[i][j] for j in selected] or [0])
                for i in candidates
            ]
            chosen = candidates[np.argmax(scores)]
            selected.append(chosen)
            candidates.remove(chosen)

        return selected
    
    def _get_user_profile(self, user_id: str):
        """Get user profile from database."""
        if not self._db_profile_service or not user_id:
            return None
        try:
            profile = self._db_profile_service.get_user_with_progress(user_id)
            return profile
        except Exception as e:
            print(f"Error getting user profile: {e}")
            return None
    
    def _search_context(self, query: str) -> str:
        """Search for relevant TOEIC writing context using RAG with enhancement."""
        try:
            # Refine query with TF-IDF/MMR
            refined_query = self._refine_query_with_tfidf_mmr(
                query=query,
                corpus=None,
                top_n=12,
                Î»=0.7
            )

            # Search Qdrant
            results = self._vector_service.search(
                question=refined_query,
                limit=5,
                score_threshold=0.3
            )
            
            # Extract content
            retrieved = [r["payload"].get("content", "") for r in results]
            context_text = "\n".join(f"- {txt}" for txt in retrieved if txt)
            
            return context_text or "No specific context found."
            
        except Exception as e:
            print(f"âŒ RAG Error: {e}")
            return "No context available."
    
    def _create_evaluation_prompt(
        self, 
        writing_type: str,
        content: str, 
        metadata: dict,
        context: str, 
        user_profile=None
    ) -> str:
        """Create personalized evaluation prompt based on writing type."""
        
        # Type-specific prompts
        type_prompts = {
            "email-response": """
Báº¡n lÃ  má»™t **giÃ¡m kháº£o cháº¥m thi TOEIC Writing chuyÃªn nghiá»‡p** (nghiÃªm kháº¯c vÃ  chuáº©n xÃ¡c).

Nhiá»‡m vá»¥: **ÄÃ¡nh giÃ¡ bÃ i viáº¿t pháº£n há»“i email** (Email 2) dá»±a trÃªn email nháº­n Ä‘Æ°á»£c (Email 1) vÃ  yÃªu cáº§u Ä‘á» bÃ i.

**ThÃ´ng tin Ä‘á» bÃ i:**
1. **Email nháº­n Ä‘Æ°á»£c (Context):**
{context_info}

2. **YÃªu cáº§u cho email pháº£n há»“i (Topic):**
{topic}

**BÃ i lÃ m cá»§a thÃ­ sinh (Email 2):**
{title}
{content}

**YÃªu cáº§u Ä‘Ã¡nh giÃ¡:**
- BÃ i viáº¿t (Email 2) pháº£i pháº£n há»“i phÃ¹ há»£p vá»›i ná»™i dung Email 1.
- BÃ i viáº¿t pháº£i Ä‘Ã¡p á»©ng Äá»¦ vÃ  ÄÃšNG cÃ¡c yÃªu cáº§u trong pháº§n Topic (vÃ­ dá»¥: Ä‘áº·t cÃ¢u há»i, Ä‘Æ°a ra thÃ´ng tin...).
- **CHáº¤M ÄIá»‚M NGHIÃŠM KHáº®C**: KhÃ´ng cháº¥m nÆ°Æ¡ng tay. Äiá»ƒm sá»‘ pháº£i pháº£n Ã¡nh Ä‘Ãºng trÃ¬nh Ä‘á»™ thá»±c táº¿.
    - Äiá»ƒm cao (80-100): HoÃ n háº£o vá» ngá»¯ phÃ¡p, tá»« vá»±ng cao cáº¥p, máº¡ch láº¡c, Ä‘Ã¡p á»©ng má»i yÃªu cáº§u, vÄƒn phong chuyÃªn nghiá»‡p.
    - Äiá»ƒm khÃ¡ (60-79): CÃ³ lá»—i nhá» nhÆ°ng khÃ´ng áº£nh hÆ°á»Ÿng hiá»ƒu, Ä‘Ã¡p á»©ng yÃªu cáº§u chÃ­nh, tá»« vá»±ng khÃ¡.
    - Äiá»ƒm trung bÃ¬nh (40-59): CÃ³ lá»—i ngá»¯ phÃ¡p/tá»« vá»±ng Ä‘Ã¡ng ká»ƒ, thiáº¿u Ã½ hoáº·c diá»…n Ä‘áº¡t lá»§ng cá»§ng.
    - Äiá»ƒm tháº¥p (<40): Láº¡c Ä‘á», sai ngá»¯ phÃ¡p nghiÃªm trá»ng, khÃ´ng hiá»ƒu Ä‘á».

**TiÃªu chÃ­ Ä‘Ã¡nh giÃ¡ chi tiáº¿t (thang Ä‘iá»ƒm 0-100):**
1. **Content**: Má»©c Ä‘á»™ hoÃ n thÃ nh yÃªu cáº§u (Task Fulfillment). CÃ³ tráº£ lá»i Ä‘Ãºng Email 1 vÃ  lÃ m Ä‘á»§ yÃªu cáº§u Topic khÃ´ng?
2. **Structure**: Bá»‘ cá»¥c email (ChÃ o há»i - Má»Ÿ Ä‘áº§u - Ná»™i dung chÃ­nh - Káº¿t thÃºc - KÃ½ tÃªn). Máº¡ch láº¡c vÃ  liÃªn káº¿t.
3. **Vocabulary**: Sá»± Ä‘a dáº¡ng vÃ  chÃ­nh xÃ¡c cá»§a tá»« vá»±ng. TrÃ¡nh láº·p tá»«. DÃ¹ng Ä‘Ãºng tá»« vá»±ng thÆ°Æ¡ng máº¡i/cÃ´ng sá»Ÿ.
4. **Grammar**: Äá»™ chÃ­nh xÃ¡c ngá»¯ phÃ¡p vÃ  sá»± Ä‘a dáº¡ng cáº¥u trÃºc cÃ¢u.
5. **Style**: VÄƒn phong (Tone) cÃ³ phÃ¹ há»£p khÃ´ng (trang trá»ng/thÃ¢n máº­t tÃ¹y ngá»¯ cáº£nh).
6. **Effectiveness**: Hiá»‡u quáº£ giao tiáº¿p. NgÆ°á»i nháº­n cÃ³ hiá»ƒu rÃµ vÃ  hÃ i lÃ²ng khÃ´ng?
""",
            "opinion-essay": """
Báº¡n lÃ  má»™t **giÃ¡o viÃªn tiáº¿ng Anh chuyÃªn nghiá»‡p** cÃ³ kinh nghiá»‡m Ä‘Ã¡nh giÃ¡ TOEIC Writing vÃ  IELTS Writing.

Nhiá»‡m vá»¥: **ÄÃ¡nh giÃ¡ chi tiáº¿t bÃ i viáº¿t nÃªu quan Ä‘iá»ƒm** theo tiÃªu chuáº©n TOEIC Writing Task 2.

**BÃ i viáº¿t cáº§n Ä‘Ã¡nh giÃ¡:**
{title}
{topic}
{context_info}
{required_length}

**Ná»™i dung bÃ i viáº¿t:**
{content}

**TiÃªu chÃ­ Ä‘Ã¡nh giÃ¡ chung (thang Ä‘iá»ƒm 0â€“100):**
1. **Content**: BÃ i viáº¿t pháº£n há»“i Ä‘áº§y Ä‘á»§ vÃ  chÃ­nh xÃ¡c theo ngá»¯ cáº£nh, thá»ƒ hiá»‡n quan Ä‘iá»ƒm rÃµ rÃ ng
2. **Structure**: Máº¡ch láº¡c, cÃ³ bá»‘ cá»¥c rÃµ rÃ ng (má»Ÿ bÃ i â€“ thÃ¢n bÃ i â€“ káº¿t luáº­n)
3. **Vocabulary**: Tá»« vá»±ng Ä‘a dáº¡ng, chÃ­nh xÃ¡c, phÃ¹ há»£p vá»›i ngá»¯ cáº£nh
4. **Grammar**: Cáº¥u trÃºc ngá»¯ phÃ¡p chÃ­nh xÃ¡c, linh hoáº¡t
5. **Style**: Giá»ng vÄƒn phÃ¹ há»£p vá»›i thá»ƒ loáº¡i bÃ i
6. **Effectiveness**: Láº­p luáº­n thuyáº¿t phá»¥c, cÃ³ vÃ­ dá»¥ há»£p lÃ½
""",
            "describe-picture": """
Báº¡n lÃ  má»™t **giÃ¡o viÃªn tiáº¿ng Anh chuyÃªn nghiá»‡p** cÃ³ kinh nghiá»‡m Ä‘Ã¡nh giÃ¡ **TOEIC Writing Task 1 (mÃ´ táº£ tranh)**.

Nhiá»‡m vá»¥: **ÄÃ¡nh giÃ¡ chi tiáº¿t bÃ i viáº¿t mÃ´ táº£ tranh** theo tiÃªu chuáº©n TOEIC Writing Task 1.

**ThÃ´ng tin bÃ i viáº¿t cáº§n Ä‘Ã¡nh giÃ¡:**
{title}
{topic}
{context_info}
{required_length}
{sample_answer}

**Ná»™i dung bÃ i viáº¿t:**
{content}

**TiÃªu chÃ­ Ä‘Ã¡nh giÃ¡ chung (thang Ä‘iá»ƒm 0â€“100):**
1. **Content**: MÃ´ táº£ Ä‘Æ°á»£c cÃ¡c chi tiáº¿t chÃ­nh cá»§a bá»©c tranh
2. **Organization**: BÃ i viáº¿t cÃ³ bá»‘ cá»¥c rÃµ rÃ ng, trÃ¬nh tá»± há»£p lÃ½
3. **Vocabulary**: Sá»­ dá»¥ng tá»« vá»±ng Ä‘a dáº¡ng, chÃ­nh xÃ¡c
4. **Grammar**: DÃ¹ng cáº¥u trÃºc ngá»¯ phÃ¡p chÃ­nh xÃ¡c, linh hoáº¡t
5. **Style**: NgÃ´n ngá»¯ tá»± nhiÃªn, phÃ¹ há»£p vá»›i vÄƒn phong miÃªu táº£
6. **Clarity & Fluency**: CÃ¢u vÄƒn trÃ´i cháº£y, dá»… hiá»ƒu
"""
        }
        
        # Get base prompt for type
        base_prompt = type_prompts.get(writing_type, type_prompts["opinion-essay"])
        
        # Format with metadata
        title = f"Subject: {metadata.get('title')}" if metadata.get('title') else ""
        # Topic lÃ  yÃªu cáº§u Ä‘á» bÃ i
        topic = metadata.get('topic', "KhÃ´ng cÃ³ yÃªu cáº§u cá»¥ thá»ƒ")
        # Context lÃ  ná»™i dung email nháº­n Ä‘Æ°á»£c
        context_info = metadata.get('context', "KhÃ´ng cÃ³ ná»™i dung email gá»‘c")
        
        required_length = f"Sá»‘ tá»« yÃªu cáº§u: {metadata.get('requiredLength')}" if metadata.get('requiredLength') else ""
        sample_answer = f"ÄÃ¡p Ã¡n máº«u: {metadata.get('sampleAnswer')}" if metadata.get('sampleAnswer') else ""
        
        base_prompt = base_prompt.format(
            title=title,
            content=content,
            topic=topic,
            context_info=context_info,
            required_length=required_length,
            sample_answer=sample_answer
        )
        
        # Add personalization if available
        if user_profile and PERSONALIZATION_AVAILABLE:
            personalization_ctx = get_personalization_context(user_profile)
            user_name = user_profile.display_name if hasattr(user_profile, 'display_name') else "báº¡n"
            learning_style = personalization_ctx.get("learning_style", "balanced")
            personality_type = personalization_ctx.get("personality", "encouraging")
            
            base_prompt += f"""

**ThÃ´ng tin ngÆ°á»i há»c:**
- TÃªn: {user_name}
- Phong cÃ¡ch há»c: {learning_style}
- TÃ­nh cÃ¡ch: {personality_type}

HÃ£y cÃ¡ nhÃ¢n hÃ³a feedback theo phong cÃ¡ch {personality_type} vÃ  phÃ¹ há»£p vá»›i ngÆ°á»i há»c {learning_style}.
"""
        
        base_prompt += f"""

**Ngá»¯ cáº£nh tham kháº£o tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u:**
{context}

**YÃªu cáº§u pháº£n há»“i:**
- ÄÃ¡nh giÃ¡ khÃ¡ch quan, cÃ´ng báº±ng
- Pháº£n há»“i xÃ¢y dá»±ng vÃ  khÃ­ch lá»‡
- Cung cáº¥p vÃ­ dá»¥ cáº£i thiá»‡n cá»¥ thá»ƒ
- Æ¯á»›c tÃ­nh Ä‘iá»ƒm TOEIC Writing (scale 0-200)

Tráº£ vá» JSON theo cáº¥u trÃºc:
{{
  "type": "{writing_type}",
  "overallScore": number,
  "breakdown": {{
    "content": number,
    "structure": number,
    "vocabulary": number,
    "grammar": number,
    "style": number,
    "effectiveness": number
  }},
  "strengths": [string],
  "weaknesses": [string],
  "grammarErrors": [
    {{
      "type": string,
      "error": string,
      "correction": string,
      "explanation": string
    }}
  ],
  "vocabularyFeedback": {{
    "range": number,
    "accuracy": number,
    "appropriateness": number,
    "improvements": [
      {{
        "original": string,
        "suggested": string,
        "reason": string
      }}
    ]
  }},
  "structureAnalysis": {{
    "organization": number,
    "flow": number,
    "transitions": number,
    "feedback": string
  }},
  "improvementSuggestions": [string],
  "rewrittenVersion": string (optional),
  "estimatedTOEICScore": number
}}
"""
        
        return base_prompt
    
    def _parse_ai_response(self, response_text: str) -> dict:
        """Parse and clean AI response."""
        try:
            if not response_text or not response_text.strip():
                raise Exception("AI response is empty")
            
            # Log the raw response for debugging
            print(f"ğŸ“ Raw AI response (first 500 chars): {response_text[:500]}")
            
            # Try to extract JSON from markdown code block first
            json_match = re.search(r'```json\s*\n(.*?)\n```', response_text, re.DOTALL)
            if json_match:
                cleaned = json_match.group(1).strip()
                print(f"âœ… Extracted JSON from markdown code block")
            else:
                # Fallback: remove markdown code blocks if present
                cleaned = re.sub(r"^```json\n|```$", "", response_text.strip(), flags=re.MULTILINE)
                print(f"âš ï¸ No markdown code block found, using fallback cleaning")
            
            # Try to parse JSON
            result = json.loads(cleaned)
            print(f"âœ… Successfully parsed JSON")
            return result
            
        except json.JSONDecodeError as e:
            print(f"âŒ JSON Parse Error: {str(e)}")
            print(f"ğŸ“„ Failed response text: {response_text[:1000]}")
            raise Exception(f"Failed to parse AI response as JSON: {str(e)}")
        except Exception as e:
            print(f"âŒ Unexpected error in parsing: {str(e)}")
            raise Exception(f"Failed to parse AI response: {str(e)}")
    
    def _update_user_writing_progress(self, user_id: str, evaluation: dict):
        """Update user's writing skill progress based on evaluation."""
        try:
            if not self._db_profile_service or not user_id:
                return
            
            # Calculate progress increment based on score
            overall_score = evaluation.get("overallScore", 0)
            progress_increment = 0.01 if overall_score >= 70 else 0.005
            
            # Update writing skill
            skill_updates = {
                "writing": progress_increment
            }
            
            # Also update grammar/vocabulary if scores are good
            breakdown = evaluation.get("breakdown", {})
            if breakdown.get("grammar", 0) >= 70:
                skill_updates["grammar"] = progress_increment * 0.5
            if breakdown.get("vocabulary", 0) >= 70:
                skill_updates["vocabulary"] = progress_increment * 0.5
            
            self._db_profile_service.update_user_progress(user_id, skill_updates)
            print(f"âœ… Updated writing progress for user {user_id}")
            
        except Exception as e:
            print(f"Error updating writing progress: {e}")
    
    async def evaluate_writing(
        self, 
        content: str,
        writing_type: str,
        metadata: Optional[dict] = None,
        user_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Evaluate TOEIC writing with optional personalization.
        
        Args:
            content: The writing content to evaluate
            writing_type: Type of writing (email-response, opinion-essay, describe-picture)
            metadata: Additional metadata (title, topic, context, etc.)
            user_id: Optional user ID for personalization
            
        Returns:
            Structured evaluation result with scores, feedback, and suggestions
        """
        try:
            # Validate writing type
            valid_types = ["email-response", "opinion-essay", "describe-picture"]
            if writing_type not in valid_types:
                raise ValueError(f"Invalid writing type. Must be one of: {valid_types}")
            
            # Default metadata
            if metadata is None:
                metadata = {}
            
            # Get user profile if available
            user_profile = None
            if user_id:
                user_profile = self._get_user_profile(user_id)
            
            # Search for relevant context
            search_query = f"TOEIC writing {writing_type} evaluation criteria examples guidelines"
            context = self._search_context(search_query)
            
            # Create personalized prompt
            prompt = self._create_evaluation_prompt(
                writing_type, content, metadata, context, user_profile
            )
            
            print(f"ğŸ¤– Calling Gemini for writing evaluation...")
            print(f"ğŸ“Š Writing type: {writing_type}, Content length: {len(content)} chars")
            
            # Call Gemini for evaluation
            from langchain.schema.messages import HumanMessage
            result = self._llm.invoke([HumanMessage(content=prompt)])
            
            print(f"âœ… Gemini response received, length: {len(result.content) if result.content else 0} chars")
            
            # Parse response
            evaluation = self._parse_ai_response(result.content)
            
            # Update user progress if user_id provided
            if user_id:
                self._update_user_writing_progress(user_id, evaluation)
            
            # Add metadata
            evaluation["metadata"] = {
                "personalized": user_profile is not None,
                "user_id": user_id,
                "context_used": bool(context and context != "No context available."),
                "writing_type": writing_type
            }
            
            return evaluation
            
        except Exception as e:
            print(f"âŒ Evaluation failed: {e}")
            raise Exception(f"Failed to evaluate writing: {str(e)}")
